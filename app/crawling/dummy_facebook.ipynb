{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e351bcbc",
   "metadata": {},
   "source": [
    "This code used to test some of the functions that were used, in case there's issue in a single function that disturb another functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79bf169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import pymongo\n",
    "import json\n",
    "import schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cfbdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"johnwick67319@gmail.com\"\n",
    "password = \"herofavorit123\"\n",
    "driver = None\n",
    "target = \"https://www.facebook.com/cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086fca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_driver():\n",
    "    options = webdriver.EdgeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "    driver = webdriver.Edge(options=options)\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1918c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_human_typing(element, text):\n",
    "    for char in text:\n",
    "        element.send_keys(char)\n",
    "        time.sleep(random.uniform(0.1, 0.5))\n",
    "        if random.random() < 0.2:\n",
    "            time.sleep(random.uniform(0.3, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcae6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(driver, email, password):\n",
    "    driver.get(\"https://www.facebook.com/login\")\n",
    "\n",
    "    email_input = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.NAME, \"email\"))\n",
    "    )\n",
    "    simulate_human_typing(email_input, email)\n",
    "\n",
    "    password_input = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.NAME, \"pass\"))\n",
    "    )\n",
    "    simulate_human_typing(password_input, password)\n",
    "\n",
    "    login_button = driver.find_element(By.XPATH, \"//button[@type='submit']\")\n",
    "    ActionChains(driver)\\\n",
    "        .move_to_element(login_button)\\\n",
    "        .pause(random.uniform(0.2, 0.4))\\\n",
    "        .click()\\\n",
    "        .perform()\n",
    "\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f714187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_scroll(driver, scroll_container=None, step=300):\n",
    "    \"\"\"\n",
    "    Scrolls slowly within the specified scrollable container or the entire page.\n",
    "    \"\"\"\n",
    "    if scroll_container:\n",
    "        # Scroll within the container\n",
    "        driver.execute_script(\"arguments[0].scrollBy(0, arguments[1]);\", scroll_container, step)\n",
    "    else:\n",
    "        # Scroll the entire page\n",
    "        driver.execute_script(f\"window.scrollBy(0, {step});\")\n",
    "    \n",
    "    time.sleep(random.uniform(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62cf11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigate_to_profile(driver, target):\n",
    "    driver.get(target)\n",
    "    time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15225adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_posts_with_bs(driver):\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "    links_data = []\n",
    "    seen_links = set()\n",
    "\n",
    "    links = soup.find_all(\"div\", {\"class\": \"x1n2onr6 x1ja2u2z\"})\n",
    "\n",
    "    for link in links:\n",
    "        try:\n",
    "            link_post = link.select_one(\"div.xu06os2.x1ok221b > span > div > span > span > span > a\")\n",
    "            href = link_post.get('href') if link_post else None\n",
    "\n",
    "            # Filter: only include links that contain '/posts/' and not '/videos/'\n",
    "            if href and \"/posts/\" in href and \"/videos/\" not in href and href not in seen_links:\n",
    "                links_data.append(href)\n",
    "                seen_links.add(href)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Error extracting link data:\", e)\n",
    "\n",
    "    return links_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db173de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_link(driver, max_links):\n",
    "    all_links = []\n",
    "\n",
    "    while len(all_links) < max_links:\n",
    "        links = extract_posts_with_bs(driver)\n",
    "        new_links = [link for link in links if link not in all_links]\n",
    "        all_links.extend(new_links)\n",
    "        print(f\"Extracted {len(all_links)} unique posts so far.\")\n",
    "        slow_scroll(driver, step=500)\n",
    "\n",
    "        if len(all_links) >= max_links:\n",
    "            break\n",
    "\n",
    "    return all_links[:max_links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_all_see_more(driver, timeout=5):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while time.time() - start_time < timeout:\n",
    "        try:\n",
    "            see_more_buttons = driver.find_elements(By.XPATH, \"//div[@role='button' and contains(text(), 'See more')]\")\n",
    "            if not see_more_buttons:\n",
    "                break\n",
    "\n",
    "            for btn in see_more_buttons:\n",
    "                try:\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", btn)\n",
    "                    time.sleep(0.5)\n",
    "                    btn.click()\n",
    "                    time.sleep(1)\n",
    "                except Exception as click_error:\n",
    "                    continue  # Some buttons may disappear; skip errors\n",
    "        except Exception as e:\n",
    "            break\n",
    "        \n",
    "        time.sleep(2)  # Pause before re-checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf4ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_comments_from_post(driver, post_url, max_comments):\n",
    "    driver.get(post_url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    comments = []\n",
    "    previous_comments_count = 0\n",
    "    scroll_container = driver.find_element(By.CSS_SELECTOR, \"div.xb57i2i.x1q594ok.x5lxg6s.x78zum5.xdt5ytf.x6ikm8r.x1ja2u2z.x1pq812k.x1rohswg.xfk6m8.x1yqm8si.xjx87ck.xx8ngbg.xwo3gff.x1n2onr6.x1oyok0e.x1odjw0f.x1iyjqo2.xy5w88m\")\n",
    "\n",
    "    button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//div[@role='button' and .//span[text()='Most relevant']]\"))\n",
    "        )\n",
    "    button.click()\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    all_comments_btn = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//div[@role='menuitem']//span[text()='All comments']\"))\n",
    "    )\n",
    "    all_comments_btn.click()\n",
    "\n",
    "    while len(comments) < max_comments:\n",
    "        click_all_see_more(driver)\n",
    "        slow_scroll(driver, scroll_container=scroll_container, step=500)\n",
    "        print(\"[[Comments Len:\", len(comments))\n",
    "\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        comment_elements = soup.find_all(\"div\", {\"class\": \"x16hk5td x12rz0ws\"})\n",
    "\n",
    "        for comment in comment_elements:\n",
    "            try:\n",
    "                username = comment.find(\"span\", {\"class\": \"x3nfvp2\"}).text.strip()\n",
    "                text = comment.find(\"span\", {\"class\": \"xudqn12\"}).text.strip()\n",
    "\n",
    "                if {\"username\": username, \"comment\": text} not in comments:\n",
    "                    comments.append({\"username\": username, \"comment\": text})\n",
    "            except Exception as e:\n",
    "                print(\"Error extracting comment:\", e)\n",
    "\n",
    "        if len(comments) >= max_comments:\n",
    "            print(f\"Collected {max_comments} comments. Stopping.\")\n",
    "            break\n",
    "\n",
    "    return comments[:max_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1dc0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visit_links(driver, post_links):\n",
    "    all_comments = []\n",
    "\n",
    "    for post_link in post_links:\n",
    "        print(f\"Scraping comments from post: {post_link}\")\n",
    "        comments = extract_comments_from_post(driver, post_link, 30)\n",
    "        \n",
    "        # Print the post link and its comments\n",
    "        print(f\"\\nPost Link: {post_link}\")\n",
    "        if comments:\n",
    "            for idx, comment in enumerate(comments, start=1):\n",
    "                print(f\"{idx}. Username: {comment['username']}, Comment: {comment['comment']}\")\n",
    "                all_comments.append({\n",
    "                    \"URL\": post_link,\n",
    "                    \"Username\": comment[\"username\"],\n",
    "                    \"Comment\": comment[\"comment\"]\n",
    "                })\n",
    "        else:\n",
    "            print(\"No comments found for this post.\")\n",
    "        \n",
    "        print(\"-\" * 80)  # Separator for readability\n",
    "\n",
    "    return all_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f400b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mongo(data):\n",
    "    client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "    db = client[\"db_analisis_sentimen\"]\n",
    "    collection = db[\"facebook\"]\n",
    "\n",
    "    inserted_count = 0\n",
    "    for item in data:\n",
    "        existing = collection.find_one({\n",
    "            \"URL\": item[\"URL\"],\n",
    "            \"Username\": item[\"Username\"],\n",
    "            \"Comment\": item[\"Comment\"]\n",
    "        })\n",
    "\n",
    "        if not existing:\n",
    "            collection.insert_one(item)\n",
    "            inserted_count += 1\n",
    "\n",
    "    print(f\"Saved {inserted_count} new comments to MongoDB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8732fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = initialize_driver()\n",
    "\n",
    "login(driver, email, password)\n",
    "\n",
    "navigate_to_profile(driver, target)\n",
    "\n",
    "post_links = take_link(driver, max_links=5)\n",
    "\n",
    "all_comments = visit_links(driver, post_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545bb863",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_comments:\n",
    "    save_mongo(all_comments)\n",
    "else:\n",
    "    print(\"No comments were scraped?\")\n",
    "\n",
    "time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
